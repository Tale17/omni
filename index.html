<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Learning disentangled visual concepts to generate different concepts in a reference image or combine concepts from different images.">
  <meta name="keywords" content="Concept Disentangle, Diffusion, Image Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OmniPrism: Learning Disentangled Visual Concept for Image Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">OmniPrism: Learning Disentangled Visual Concept for Image Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/Tale17">Yangyang Li</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://daqingliu.github.io/">Daqing Liu</a><sup>2✝</sup>,</span>
            <span class="author-block">
              <a href="https://faculty.ustc.edu.cn/liuwu">Wu Liu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Allen He</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://xinchenliu.com">Xinchen Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=hxGs4ukAAAAJ">Yongdong Zhang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://dblp.org/pid/61/9936">Guoqing Jin</a><sup>3✉</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China,</span>
            <span class="author-block"><sup>2</sup>JD Explore Academy, JD.com Inc.</span>
            <span class="author-block"><sup>3</sup>State Key Laboratory of Communication Content Cognition, People’s Daily Online</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>✝</sup>Project lead,</span>&nbsp;
            <span class="author-block"><sup>✉</sup>Corresponding author,</span>&nbsp
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Tale17/OmniPrism"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 主图. -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/fig1.jpg"
       class="interpolation-image"
       alt="Interpolate start reference image."/>
      <h2 class="content has-text-centered">
        <p>
          <span class="dnerf">We</span> propose OmniPrism, which arbitrarily disentangles and combines visual concepts. 
          (a) Disentangled visual concept generation. Given a reference image with multiple concepts, 
          our method can disentangle the desired concept guided by natural language such as content names 
          (red color words in prompts), “style” or “composition” (e.g., relation or structural features 
          like pose) while remaining faithful to prompts. (b) Multi-concept combination. Given two or more 
          reference images with the corresponding concept guidance, our approach can combine all desired 
          concepts in any combination without conflicts.
        </p>
        <p>
          Based on OmniPrism, we can also achieve more applications, such as <a href="#combina">multi-content combination</a>, <a href="#blend">concept blending</a>, and <a href="#control">combine with ControlNet</a>.
        </p>
      </h2>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Creative visual concept generation often draws inspiration from specific concepts in a reference image to produce relevant outcomes.
            However, existing methods are typically constrained to single-aspect concept generation or are easily disrupted by irrelevant concepts in multi-aspect concept scenarios, leading to concept confusion and hindering creative generation. 
            To address this, we propose OmniPrism, a visual concept disentangling approach for creative image generation.
            Our method learns disentangled concept representations guided by natural language and trains a diffusion model to incorporate these concepts.
            We utilize the rich semantic space of a multimodal extractor to achieve concept disentanglement from given images and concept guidance.
            To disentangle concepts with different semantics, we construct a paired concept disentangled dataset (PCD-200K), where each pair shares the same concept such as content, style, and composition.
            We learn disentangled concept representations through our contrastive orthogonal disentangled (COD) training pipeline, which are then injected into additional diffusion cross-attention layers for generation.
            A set of block embeddings is designed to adapt each block's concept domain in the diffusion models.
            Extensive experiments demonstrate that our method can generate high-quality, concept-disentangled results with high fidelity to text prompts and desired concepts. Our codes, models, and datasets will be available upon acceptance.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Method</h2>
        <h2 class="title is-4">Framework</h2>
        <img src="./static/images/method.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
        <div class="content has-text-justified">
          <p>
            Given a reference image, text prompt and concept guidance, 
            we use Concept Extractor to extract the specified concept in 
            the image and then send it to diffusion model to generate corresponding concepts. 
            We use the Contrastive Orthogonal Disentangled Learning constraint model to learn 
            concept disentanglement.
          </p>
        </div>
        <h2 class="title is-4">Paired Concept Disentangled Dataset</h2>
        <img src="./static/images/dataset.png"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
        <div class="content has-text-justified">
          <p>
            We design three data construction pipelines for the three concepts of <code>content</code>, 
            <code>style</code>, and <code>composition</code>, each pipeline uses GPT-4o to obtain 
            reference prompts <span class="mathjax"><i>I</i><sub>ref</sub></span>, target prompts 
            <span class="mathjax"><i>I</i><sub>tar</sub></span>, and concept guidance <span class="mathjax"><i>T</i><sub>cg</sub></span>, 
            and use different models to generate corresponding reference images <span class="mathjax"><i>I</i><sub>ref</sub></span> 
            and target images <span class="mathjax"><i>I</i><sub>tar</sub></span>.
          <p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>

<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <!-- Main Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Main Results</h2>
        <img src="./static/images/case.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
      </div>
    </div>
    <!--/ Main Results. -->
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <!-- Comparisons. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Comparisons with State-of-the-Arts</h2>
        <img src="./static/images/compare.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
        <div class="content has-text-justified">
          <p>
            Given a reference image with various concepts, our OmniPrism achieves superior disentangled generation performance. It not only avoids introducing irrelevant concepts but also ensures the highest concept and prompt fidelity and image quality.
          <p>
        </div>
        <img src="./static/images/table1.png"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
        <div class="content has-text-justified">
          <p>
            OmniPrism achieves the highest Mask CLIP-I, CLIP-T scores and image quality, and the best balance between Style Similarity and other metrics.
          <p>
        </div>
      </div>
    </div>
    <!--/ Comparisons. -->
  </div>
</section>

<section class="section hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- App. -->
      <h2 class="title is-2 has-text-centered">Applications</h2>
        <!-- combina. -->
        <div class="column is-full-width">
          <h2 id="combina", class="title is-4 has-text-centered">Multi-Content Combinations</h2>
          <img src="./static/images/multi_obj.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          <div class="content has-text-justified">
            <p>
              We use latent masks to assign layouts to different concepts to prevent them from conflicting.
            <p>
          </div>
        </div>
        <!-- combina. -->
        <!-- blend -->
        <div class="column is-full-width">
          <h2 id="blend", class="title is-4  has-text-centered">Concept Blending</h2>
          <img src="./static/images/blend.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
        </div>
        <!-- blend -->
        <!-- controlnet -->
        <div id="control", class="column is-full-width">
          <h2 class="title is-4  has-text-centered">OmniPrism with ControlNet </h2>
          <img src="./static/images/ctrl_omni.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
        </div>
        <!-- controlnet -->

      <!--/ App. -->
    </div>
  </div>
</section>

<section class="section hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- More Result. -->
      <h2 class="title is-2 has-text-centered">More Result</h2>
      <!-- base model. -->
      <div class="column is-full-width">
        <h2 class="title is-4 has-text-centered">Different Base model</h2>
        <img src="./static/images/diff_model.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
      </div>
      <!-- base model. -->
      <!-- obj. -->
      <div class="column is-full-width">
        <h2 class="title is-4 has-text-centered">Content Disentangle Results</h2>
        <img src="./static/images/more_obj.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
      </div>
      <!-- obj. -->
      <!-- style -->
      <div class="column is-full-width">
        <h2 class="title is-4 has-text-centered">Style Disentangle Results</h2>
        <img src="./static/images/more_style.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
      </div>
      <!-- style -->
      <!-- composition -->
      <div class="column is-full-width">
        <h2 class="title is-4 has-text-centered">Composition Disentangle Results</h2>
        <img src="./static/images/more_pose.jpg"
          class="interpolation-image"
          alt="Interpolate start reference image."/>
      </div>
      <!-- composition -->
      <!--/ More Result. -->
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
